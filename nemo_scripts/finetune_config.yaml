name: "FastConformer-Hybrid-Transducer-CTC-BPE-Finetuning"

# Use pretrained model via Hydra init override
init_from_nemo_model: null
init_from_pretrained_model: null

model:
  sample_rate: 16000
  compute_eval_loss: false
  log_prediction: true
  skip_nan_grad: false

  train_ds:
    manifest_filepath: null
    sample_rate: ${model.sample_rate}
    batch_size: 32
    shuffle: true
    num_workers: 8
    pin_memory: true
    max_duration: 20
    min_duration: 0.5
    is_tarred: false
    tarred_audio_filepaths: null
    shuffle_n: 2048
    bucketing_strategy: "synced_randomized"
    bucketing_batch_size: null

  validation_ds:
    manifest_filepath: null
    sample_rate: ${model.sample_rate}
    batch_size: 32
    shuffle: false
    use_start_end_token: false
    num_workers: 8
    pin_memory: true

  test_ds:
    manifest_filepath: null
    sample_rate: ${model.sample_rate}
    batch_size: 32
    shuffle: false
    use_start_end_token: false
    num_workers: 8
    pin_memory: true

  optim:
    name: adamw
    lr: 0.0001  # Fine-tuning learning rate
    betas: [0.9, 0.999]
    weight_decay: 0.0001
    sched:
      name: CosineAnnealing
      warmup_steps: 1000
      warmup_ratio: null
      min_lr: 1e-6

trainer:
  devices: -1  # Use all GPUs
  num_nodes: 1
  max_epochs: 50
  max_steps: -1
  val_check_interval: 1.0
  accelerator: gpu
  strategy: ddp  # Use DDP strategy
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0
  precision: bf16-mixed
  log_every_n_steps: 50
  enable_progress_bar: true
  num_sanity_val_steps: 0
  check_val_every_n_epoch: 1
  sync_batchnorm: true
  enable_checkpointing: false  # Managed by exp_manager
  logger: false  # Managed by exp_manager
  benchmark: false

exp_manager:
  exp_dir: null
  name: ${name}
  create_tensorboard_logger: true
  create_checkpoint_callback: true
  checkpoint_callback_params:
    monitor: "val_wer"
    mode: "min"
    save_top_k: 3
    always_save_nemo: true
  resume_from_checkpoint: null
  resume_if_exists: false
  resume_ignore_no_checkpoint: false
  create_wandb_logger: false
